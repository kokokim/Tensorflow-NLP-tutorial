{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiESDsdkMziwFqwa79zxKW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 양방향 LSTM과 바다나우 어텐션 매커니즘으로 IMDB 리뷰감성 분류하기"],"metadata":{"id":"sJsezR30EE86"}},{"cell_type":"markdown","source":["### 1. IMDB 리뷰 데이터 전처리하기\n","* IMDB 리뷰 데이터\n","  * 영화 리뷰 데이터\n","  * 이미 훈련 데이터와 테스트 데이터를 50:50 비율로 구분해서 제공\n","  * x 데이터\n","    * 텍스트 전처리 되어 있음 (토큰화, 정수 인코딩)\n","    * 등장 빈도에 따라 인덱스 부여\n","  * y 데이터\n","    * 긍정(1), 부정(0)\n"],"metadata":{"id":"EPyhWpZADxv6"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"2N3utS0TENKl","executionInfo":{"status":"ok","timestamp":1721298619846,"user_tz":-540,"elapsed":8575,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["vocab_size=10000 #단어 집합의 크기\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n","#num_words는 해당 데이터에서 등장 빈도 순위로 몇 등까지의 단어를 사용할 것인지를 의미"],"metadata":{"id":"hcN4FIbDEUwY","executionInfo":{"status":"ok","timestamp":1721298625799,"user_tz":-540,"elapsed":5959,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7df57dae-8aed-4cf6-e2e7-6d49613544ec"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["print(len(X_train))\n","print(len(X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OgLnpCKElSH","executionInfo":{"status":"ok","timestamp":1721298625800,"user_tz":-540,"elapsed":14,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"outputId":"281f9313-3e9c-4276-9dd7-0a793da63b53"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["25000\n","25000\n"]}]},{"cell_type":"code","source":["print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n","print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mf37_caHFY9v","executionInfo":{"status":"ok","timestamp":1721298625800,"user_tz":-540,"elapsed":12,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"outputId":"f8edf015-d581-4c6b-d761-399c85d67095"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["리뷰의 최대 길이 : 2494\n","리뷰의 평균 길이 : 238.71364\n"]}]},{"cell_type":"code","source":["max_len = 500 #평균 길이보다 조금 더 크게 데이터 패딩할거에요오\n","#근데 여기 질문!! 최대 길이가 2094인 리뷰는 500으로 패딩하면 어떻게 되지...?\n","#리뷰의 앞쪽 일부가 잘리고 마지막 500개의 토큰만 남게됨.\n","#pad_sequences 함수는 기본적으로 시퀀스의 뒤쪽이 아닌 앞쪽에서 잘라내는 기능을 함 -> 앞에 잘림!\n","X_train = pad_sequences(X_train, maxlen=max_len)\n","X_test = pad_sequences(X_test, maxlen=max_len)"],"metadata":{"id":"9XwEzjlrGPIS","executionInfo":{"status":"ok","timestamp":1721298626639,"user_tz":-540,"elapsed":850,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## 2. 바다나우 어텐션(Bahdanau Attention)\n","* 어텐션 스코어\n","  * ![image.png](data:image/png;base64,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)\n"],"metadata":{"id":"qMvzYGi5Zakw"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"Mdblw5RKZDu7","executionInfo":{"status":"ok","timestamp":1721298927387,"user_tz":-540,"elapsed":339,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#BahdanauAttention 클래스의 인스턴스를 생성하고 호출할 때, call 메서드가 자동으로 실행된다\n","#왜? Tensorflow의 tf.keras.Model 클래스를 상속받아서\n","\n","class BahdanauAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = Dense(units)\n","    self.W2 = Dense(units)\n","    self.V = Dense(1) #V는 W의 a의 T를 말함. 입력 벡터를 1차원으로 변환하는 완전 연결층을 만든다는 것을 의미\n","\n","  def call(self, values, query): #key와 value는 같음 -> 인코더의 은닉상태 벡터들 hs\n","    # query shape == (batch_size, hidden size)\n","    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해주자\n","    hidden_with_time_axis = tf.expand_dims(query, 1) #차원 1개 추가\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # 마지막 축에 1이 있는 이유 -> self.v를 score에 적용하기 때문\n","    # self.v를 적용하기 전의 텐서 형태 -> (batch_size, max_lenth, units) 이다.\n","    # units은 모델의 특정 레이어에서 사용되는 뉴런의 수 또는 차원의 크기를 의미 (각 시퀀스의 각 단어에 대해 units 크기의 벡터를 가진 텐서임을 의미)\n","    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis))) #value는 key랑 같다. key가 들어가야하는데 같으므로 value 사용\n","    # 여기서 이 코드가 알아서 t-1 시점의 디코더 셀의 숨겨진 상태를 사용해서 연산을 진행함\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1) #가중치를 구하기 위해서 점수를 softmax함\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1) #각 시점별로 가중치 부여한 벡터들을 합산해서 최종 컨텍스트 벡터 생성\n","    #reduce_sum은 텐서의 모든 성분의 총합을 계산하는 함수이다.\n","\n","    return context_vector, attention_weights\n","\n",""],"metadata":{"id":"Yvn3TZ_WaTwH","executionInfo":{"status":"ok","timestamp":1721299605548,"user_tz":-540,"elapsed":332,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## 3. 양방향 LSTM + 바다나우 어텐션"],"metadata":{"id":"SfptCHHac6w_"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras import optimizers\n","import os"],"metadata":{"id":"K5nLMEm6c5T1","executionInfo":{"status":"ok","timestamp":1721299630783,"user_tz":-540,"elapsed":354,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["#### Encoder & Decoder\n","* 인코더와 디코더를 명확하게 나누지 않고 하나의 코드 블록에서 정의하고 있음\n","  * 인코더는 입력 시퀀스를 받아 상태 벡터로 변환\n","  * 디코더는 이 상태 벡터를 초기 상태로 사용하여 출력 시퀀스를 생성\n","  * attention mechanism은 디코더가 더 나은 예측을 할 수 있도록 인코더의 모든 출력을 참고\n"],"metadata":{"id":"nAijM_iLfbQd"}},{"cell_type":"code","source":["#입력층과 임베딩층 설계\n","#max_len개의 단어들을 128차원의 벡터로 임베딩하도록 설계\n","\n","sequence_input= Input(shape=(max_len,), dtype='int32')\n","embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"],"metadata":{"id":"Kc0j19rPc_eZ","executionInfo":{"status":"ok","timestamp":1721299744763,"user_tz":-540,"elapsed":337,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#양방향 lstm 설계(2층으로)\n","\n","lstm=Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(embedded_sequences) #두번째 층을 쌓을거니깐 return_sequences를 True로 해줘야함\n","lstm, forward_h, forward_c, backward_h, backward_c=Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n","\n","# Bidirectional : 양방향 RNN\n","# 64 : LSTM 유닛의 수 (LSTM 셀은 64차원의 출력 벡터를 생성)\n","# return_sequences = True : True면 LSTM 레이어는 시퀀스의 각 시점에 대한 출력을 반환함. False이면 마지막 시점의 출력만 반환\n","# return_state=True : True이면 LSTM 레이어는 마지막 타입스텝의 숨겨진 상태와 셀 상태를 반환\n","# forward_h, forward_c, backward_h, backward_c : 정방향/역방향 LSTM의 마지막 타임스텝의 숨겨진 상태(은닉상태), 셀상태(기억셀)"],"metadata":{"id":"W9ZPqyBwdYGS","executionInfo":{"status":"ok","timestamp":1721299917653,"user_tz":-540,"elapsed":4921,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 각상태의 크기 SHAPE 출력\n","\n","print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OvLVFPaneEZa","executionInfo":{"status":"ok","timestamp":1721300248453,"user_tz":-540,"elapsed":356,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"outputId":"33ee39d7-c103-407c-dabc-41f8b79558e8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"]}]},{"cell_type":"code","source":["# 정방향, 역방향 상태들을 연결 -> 은닉상태는 인코더의 hs 의미\n","\n","state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n","state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"],"metadata":{"id":"LQ9WhzP-fWRi","executionInfo":{"status":"ok","timestamp":1721300349575,"user_tz":-540,"elapsed":377,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 은닉상태를 사용해서 컨텍스트 벡터를 얻어보자 -> 디코더의 t-1시점의 은닉상태벡터와 인코더의 은닉상태벡터들을 사용해서\n","\n","attention=BahdanauAttention(64) #가중치 크기 정의\n","context_vector, attention_weights=attention(lstm, state_h) # call 메서드 호출됨."],"metadata":{"id":"FVX_xMHvfu9I","executionInfo":{"status":"ok","timestamp":1721301617325,"user_tz":-540,"elapsed":828,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 컨텍스트 벡터를 밀집층에 통과 (Affine 계층)\n","# 이진분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수 사용\n","\n","dense1=Dense(20, activation=\"relu\")(context_vector)\n","dropout=Dropout(0.5)(dense1)\n","output=Dense(1, activation=\"sigmoid\")(dropout)\n","model=Model(inputs=sequence_input, outputs=output)"],"metadata":{"id":"6iZCLqkfkkWt","executionInfo":{"status":"ok","timestamp":1721301708972,"user_tz":-540,"elapsed":362,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#모델 컴파일\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"LSpqtlMmk5Y0","executionInfo":{"status":"ok","timestamp":1721302014884,"user_tz":-540,"elapsed":348,"user":{"displayName":"SSona","userId":"09932552363696234808"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#검증데이터로 테스트 데이터를 사용해서 에폭이 끝날때마다 테스트 데이터에 대한 정확도 출력\n","history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmb9xabzlNXv","executionInfo":{"status":"ok","timestamp":1721305540385,"user_tz":-540,"elapsed":379593,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"outputId":"0885a25b-00d1-4015-813a-ed55f18cec4e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","98/98 [==============================] - 1177s 12s/step - loss: 0.4663 - accuracy: 0.7664 - val_loss: 0.2859 - val_accuracy: 0.8817\n","Epoch 2/3\n","98/98 [==============================] - 1154s 12s/step - loss: 0.2417 - accuracy: 0.9132 - val_loss: 0.2901 - val_accuracy: 0.8834\n","Epoch 3/3\n","98/98 [==============================] - 1149s 12s/step - loss: 0.1797 - accuracy: 0.9384 - val_loss: 0.3324 - val_accuracy: 0.8752\n"]}]},{"cell_type":"code","source":["print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n","\n","#대략 87%의 정확도를 얻었다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXX-yKOrlaA0","executionInfo":{"status":"ok","timestamp":1721305862511,"user_tz":-540,"elapsed":322124,"user":{"displayName":"SSona","userId":"09932552363696234808"}},"outputId":"81639bb8-70a3-4b74-936a-caa9d180ffc4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 315s 403ms/step - loss: 0.3324 - accuracy: 0.8752\n","\n"," 테스트 정확도: 0.8752\n"]}]},{"cell_type":"markdown","source":["## 정리\n","* 양방향lstm + 바다나우어텐션 사용해서 리뷰에 대한 감성분석을 수행했다. (긍정은 1, 부정은 0 -> 이진분류)\n","  * 양방향 lstm\n","    * 임베딩 텍스트 벡터를 lstm에 forward, backward를 양방향으로 수행해 앞뒤의 단어위치정보가 저장된 은닉상태벡터들을 추출\n","  * 바다나우 attention\n","    * 이와 디코더의 각 시점-1의 은닉상태벡터를 사용해 context vector 추출\n","  * 디코더\n","    * context vector와 디코더의 은닉상태벡터를 사용해 affine 계층으로 보내고 이진분류이므로 활성화함수로는 sigmoid를 사용해 출력\n","    * 모델 컴파일 -> 이진분류이므로 binarycrossentropy 사용하고 optimizer로는 adam 사용, 평가지표로는 정확도 사용\n","\n"],"metadata":{"id":"7mP-DXqO6rbI"}},{"cell_type":"code","source":[],"metadata":{"id":"zFrZzEkMqZBh"},"execution_count":null,"outputs":[]}]}